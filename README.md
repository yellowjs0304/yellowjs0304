## Interests   
* Computer Vision   
* Multi-modal Task   
* Natural Language Process   
* Machine Learning   
* Vision-and-Language Navigation   
* Robot Operating System(ROS)   
* Reinforcement Learning
   

## My Projects   
* [Messenger Robot System](https://github.com/yellowjs0304/MSB)   
* [PAPA app Project](https://github.com/yellowjs0304/PAPA)   
* [Places365 with Misaeng](https://github.com/yellowjs0304/Places365misaeng)   
* [AI_Homework :: YOLO, FRCNN Character Detection](https://github.com/yellowjs0304/homework_2)   
* [AI_Homework :: Seq2Seq Video Captioning](https://github.com/yellowjs0304/homework_4)   
* [Landmark based VLN](https://github.com/yellowjs0304/LandmarkVLN)   
* [Joint Multimodal Embedding based VLN](https://github.com/yellowjs0304/JMEBSVLN)   
* [Pancreas-CT Segmentation(by.Unet)](https://github.com/yellowjs0304/PancreasUnet)   
   
   

## My Papers   
* [Deep Reinforcement Learning for Visual Dialogue Agents](https://www.koreascience.or.kr/article/CFKO201826259815437.page)-2018.05, KIPS Conference    
* [Deep Reinforcement Learning for Optimizing Visual Questions](http://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE07528733&language=ko_KR)-2018.09, Journal of ICROS   
* [Real-Time Visual Grounding for Natural Language Instructions with Deep Neural Network](https://www.eiric.or.kr/literature/ser_view.php?searchCate=literature&SnxGubun=INEN&mode=total&literature=Y&SnxGubun=INME&gu=INME001G0&cmd=qryview&SnxIndxNum=223651&q1_yy=2019&q1_mm=05&rownum=2&f1=MN&q1=Jisu%20Hwang&totalCnt=3)-2019.05, KIPS Conference   
* [LVLN : A Landmark-Based Deep Neural Network Model for Vision-and-Language Navigation](http://kiss.kstudy.com/thesis/thesis-view.asp?key=3703348)-2019.09, Journal of KIPS(KTSDE)    
* [Landmark-based Search for Vision-and-Language Navigation](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE09301650)-2019.12 KSC Conference   
* [AnoVid: A Deep Neural Network-Based Tool for Video Annotation](https://www.koreascience.or.kr/article/JAKO202024852036275.page)-2020.08, Journal of KMMS   
* [시각-언어 이동을 위한 다중 모달 공동 임베딩과 역추적 탐색](http://library.kyonggi.ac.kr/search/detail/CATTOT000000675444)- Master's thesis   
* [Joint Multimodal Embedding and Backtracking Search in Vision-and-Language Navigation](https://www.mdpi.com/1424-8220/21/3/1012)-2021.02, Sensors   
   
   

## My Study(Paper Reading)
* [ROS](https://yjs-program.tistory.com/category/ROS%20.%20%20V-REP/ROS%20Tutorial)   
* [Transformer based Embedding Model](https://yjs-program.tistory.com/category/Paper%20Reading/Transformer%20based%20Embedding%20Model)
* [VLN](https://yjs-program.tistory.com/category/Paper%20Reading/Vision%20and%20Language%20Navigation%28VLN%29)   
* [Dialogue System](https://yjs-program.tistory.com/category/Paper%20Reading/Dialogue%20System)   
* [Pytorch Deep learning](https://yjs-program.tistory.com/category/%EB%94%A5%EB%9F%AC%EB%8B%9D/Pytorch%20%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EC%B4%88)
   

## Blog   
[![Tech Blog Badge](http://img.shields.io/badge/-Tech%20blog-black?style=flat-square&logo=github&link=https://yjs-program.tistory.com/)](https://yjs-program.tistory.com/)
   
   

## Contact   
[![Gmail Badge](https://img.shields.io/badge/Gmail-d14836?style=flat-square&logo=Gmail&logoColor=white&link=mailto:yellowjs0304@gmail.com)](mailto:yellowjs0304@gmail.com)


<div align=center>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fyellowjs0304&count_bg=%23198BD7&title_bg=%231C4E92&icon=python.svg&icon_color=%23FCFFFB&title=hits&edge_flat=false"/></a>
